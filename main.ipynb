{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local modules\n",
    "import exploredata\n",
    "\n",
    "\n",
    "# external libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "# scikit-learn modelling algorithms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier    \n",
    "\n",
    "# deployment libraries\n",
    "import pickle as pc\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_user_cookies_data(filename):\n",
    "    if os.path.isfile(filename):\n",
    "      return pd.read_csv(filename)\n",
    "    else:\n",
    "      return (\"Invalid file name, make sure the filename is correct and is in the same package\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCookiesData = load_user_cookies_data(\"shopping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCookiesData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCookiesData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCookiesData['Revenue'] = UserCookiesData['Revenue'].astype(int)\n",
    "UserCookiesData['Revenue'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper functions for exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_to_ints(value):\n",
    "    if value == True:\n",
    "      return 1\n",
    "    else:\n",
    "      return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(data, target, seed = 126):\n",
    "    \"\"\"\n",
    "    It splits the data into train, validate and test sets.\n",
    "    :return: three dataframes: train, validate, and test.\n",
    "    \"\"\"\n",
    "    train_validate, test = train_test_split(data, test_size=0.20, random_state=seed, stratify=data[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.30, random_state=seed,stratify=train_validate[target])\n",
    "    return train, validate, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_unencoded_data(data):\n",
    "    \"\"\"\n",
    "    It takes in a dataframe, drops duplicates, removes rows where tenure is 0, removes $ and , from\n",
    "    TotalCharges, converts TotalCharges to float, strips whitespace from all object columns, and returns\n",
    "    a train, validate, and test dataframe\n",
    "    \"\"\"\n",
    "    data.drop_duplicates(inplace = True)\n",
    "    categorical_columns = data.select_dtypes('object').columns\n",
    "\n",
    "    for column in categorical_columns:\n",
    "        data[column] = data[column].str.strip()\n",
    "    return train_validate_test_split(data, 'Revenue')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "univariate data exploratory analysis helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def freq_table(train, cat_var):\n",
    "    \"\"\"\n",
    "    It takes a dataframe and a categorical variable as input, and returns a frequency table as output\n",
    "    :return: A dataframe with the unique values of the categorical variable, the count of each unique\n",
    "    value, and the percentage of each unique value.\n",
    "    \"\"\"\n",
    "    class_labels = list(train[cat_var].unique())\n",
    "    freq_table = (\n",
    "      pd.DataFrame(\n",
    "        {cat_var: class_labels,\n",
    "        'Count': train[cat_var].value_counts(normalize=False),\n",
    "        'Percent': round(train[cat_var].value_counts(normalize=True)*100,2)\n",
    "        }))\n",
    "\n",
    "    return freq_table\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_quant(data,quantitative_variables):\n",
    "\n",
    "    descriptive_statistics = data[quantitative_variables].describe()\n",
    "    plt.figure(figsize=(8,2))\n",
    "    plot = plt.subplot(1, 2, 1)\n",
    "    plot = plt.hist(data[quantitative_variables], color='yellow')\n",
    "    plot = plt.title(quantitative_variables)\n",
    "    plot = plt.subplot(1, 2, 2)\n",
    "    plot = plt.boxplot(data[quantitative_variables])\n",
    "    plot = plt.title(quantitative_variables)\n",
    "    return plot, descriptive_statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate_categorical(data, categorical_vars):\n",
    "    \"\"\"\n",
    "    It creates a bar chart of the frequency of each category in a categorical variable.\n",
    "    :param data: the dataframe\n",
    "    :param categorical_vars: The categorical variable you want to plot\n",
    "    \"\"\"\n",
    "    frequency_table = freq_table(data, categorical_vars)\n",
    "    plt.figure(figsize=(6,3))\n",
    "    sns.barplot(x=categorical_vars, y='Count', data=frequency_table, color='lightblue')\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.title(categorical_vars)\n",
    "    plt.show()\n",
    "    print(frequency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univariate(data, categorical_vars, quantitative_vars):\n",
    "    \"\"\"\n",
    "    This function takes in a dataframe, a list of categorical variables, and a list of quantitative\n",
    "    variables. It then calls the univariate_categorical function for each categorical variable and the\n",
    "    univariate_quant function for each quantitative variable.\n",
    "    \"\"\"\n",
    "    for var in categorical_vars:\n",
    "        univariate_categorical(data, var)\n",
    "\n",
    "    for column in quantitative_vars:\n",
    "        plot, descriptive_statistics = univariate_quant(data, column)\n",
    "        plt.gca(figsize = 10)\n",
    "        plt.show(plot)\n",
    "        print(descriptive_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bivariate data analysis helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cat_by_target(data, target_variable, categorical_var):\n",
    "    \"\"\"\n",
    "    It takes a dataframe, a target variable, and a categorical variable, and plots the mean of the\n",
    "    target variable for each category of the categorical variable\n",
    "    :return: A plot\n",
    "    \"\"\"\n",
    "    p = plt.figure(figsize=(10,2))\n",
    "    p = sns.barplot(categorical_var, target_variable, data=data, alpha=.8, color='lightseagreen')\n",
    "    overall_rate = data[target_variable].mean()\n",
    "    p = plt.axhline(overall_rate, ls='--', color='gray')\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_means(data, target_variable, quantitative_vars, alt_hyp='two-sided'):\n",
    "    x = data[data[target_variable]==0][quantitative_vars]\n",
    "    y = data[data[target_variable]==1][quantitative_vars]\n",
    "    return stats.mannwhitneyu(x, y, use_continuity=True, alternative=alt_hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxen(data, target_variable, quantitative_var):\n",
    "    \"\"\"\n",
    "    It plots a boxen plot for the quantitative variable and the target variable.\n",
    "    \"\"\"\n",
    "    average = data[quantitative_var].mean()\n",
    "    p = sns.boxenplot(data=data, x=target_variable, y=quantitative_var, color='orange')\n",
    "\n",
    "    p = plt.title(quantitative_var)\n",
    "    p = plt.axhline(average, ls='--', color='black')\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_swarm(data, target_variable, quantitative_var):\n",
    "    \"\"\"\n",
    "    It plots a swarmplot of the quantitative variable against the target variable.\n",
    "    \"\"\"\n",
    "    average = data[quantitative_var].mean()\n",
    "    p = sns.swarmplot(data=data, x=target_variable, y=quantitative_var, color='lightgray')\n",
    "    p = plt.title(quantitative_var)\n",
    "    p = plt.axhline(average, ls='--', color='black')\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bivariate_quant(data, target, quantitative_var):\n",
    "    \"\"\"\n",
    "    It takes a dataframe, a target variable, and a quantitative variable, and then it prints the\n",
    "    descriptive statistics for the quantitative variable, grouped by the target variable. It also plots\n",
    "    a boxen plot of the quantitative variable, grouped by the target variable\n",
    "    \"\"\"\n",
    "    print(quantitative_var, \"\\n____________________\\n\")\n",
    "    descriptive_stats = data.groupby(target)[quantitative_var].describe()\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plot_boxen(data, target, quantitative_var)\n",
    "    # plot_swarm(data, target, quantitative_vars)\n",
    "    plt.show()\n",
    "    print(descriptive_stats, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bivariate_categorical(data, target, categorical_variable):\n",
    "    \"\"\"\n",
    "    It takes a dataframe, a target variable, and a categorical variable, and returns a crosstab of the\n",
    "    two variables and a bar chart of the crosstab\n",
    "    \"\"\"\n",
    "    ct = pd.crosstab(data[categorical_variable], data[target], margins=True)\n",
    "    plot = plot_cat_by_target(data, target, categorical_variable)\n",
    "    print(\"\\nobserved:\\n\", ct)\n",
    "    plt.show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here We will use the helper functions in the local explore.py module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the Distribution of customers on Revenue\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (13, 5)\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(UserCookiesData['Revenue'], palette = 'coolwarm_r')\n",
    "plt.title('Distribution of customers on Revenue', fontsize = 15)\n",
    "plt.xlabel('Revenue or not', fontsize = 15)\n",
    "plt.ylabel('count', fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting a pie chart for operating systems distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCookiesData['OperatingSystems'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare and split into train, validate, and test sets.\n",
    "train, validate, test = exploredata.process_unencoded_data(data = UserCookiesData )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCookiesData.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_vars = UserCookiesData.select_dtypes('object').columns\n",
    "quantitative_vars = UserCookiesData.select_dtypes('float').columns\n",
    "int_vars = UserCookiesData.select_dtypes('int').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exploring univariate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCookiesData['OperatingSystems'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code cell is plotting a pie chart of the different operating systems.\n",
    "size = [6601, 2585, 2555, 589]\n",
    "colors = ['violet', 'yellow', 'green', 'orange']\n",
    "labels = \"2\", \"1\", \"3\", \"others\"\n",
    "plt.rcParams['figure.figsize'] = (18, 7)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(size, colors = colors, labels = labels, shadow = True, autopct = '%.2f%%', startangle=90)\n",
    "plt.title('Different Operating Systems', fontsize = 30)\n",
    "plt.axis('off')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code cell is plotting a pie chart for the visitor types\n",
    "size = [10551, 1694, 85]\n",
    "explode = [0, 0, 0.1]\n",
    "labels = \"Returning Visitor\", \"New Visitor\", \"Others\"\n",
    "colors = ['blue', 'lightblue', 'orange']\n",
    "plt.rcParams['figure.figsize'] = (18, 7)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.pie(size, colors = colors, labels = labels, explode = explode, shadow = True, autopct = '%.2f%%')\n",
    "plt.title('Different Visitors', fontsize = 30)\n",
    "plt.axis('off')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploredata.univariate(UserCookiesData, categorical_vars, quantitative_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations from univariate exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Different user types with reference to region are not normally (Gaussian) distributed. This regional data has an exponential distribution. Therefore, we must be concerned with this type distribution.\n",
    "- Multiple types of traffic are not normally(Gaussian) distributed. This data has an exponential distribution.\n",
    "- More than 85% of visitors are repeat customers, which is enormous. For marketing purposes, this information can be useful.\n",
    "- 90% of people only used the top 3 browsers.\n",
    "- 95% of the users inÂ  this session cookies data uses the top 3 Operating Systems. The online will then need to concentrate on these browsers in order to grow embark on specific operations to increase customer purchases.\n",
    "- The distribution of Weekend and Revenue statistics is highly unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exploring Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCookiesData.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploredata.bivariate_categorical(data=UserCookiesData, target=\"Revenue\", categorical_variable =\"Weekend\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploredata.bivariate_categorical(data = UserCookiesData, target= 'Revenue', categorical_variable = 'OperatingSystems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploredata.bivariate_quant(data = UserCookiesData, target = 'Revenue', quantitative_var = 'PageValues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploredata.bivariate_quant(data = UserCookiesData, target = 'Revenue', quantitative_var = 'ExitRates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploredata.bivariate_quant(data = UserCookiesData, target=\"Revenue\", quantitative_var=\"BounceRates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(UserCookiesData.corr(), cmap='coolwarm', center=0, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,5])\n",
    "sns.pairplot(UserCookiesData,x_vars=['BounceRates','ExitRates'],y_vars=['BounceRates','ExitRates'],hue='Revenue',diag_kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exploredata.plot_cat_by_target(data =UserCookiesData, target_variable = \"Revenue\", categorical_var = \"VisitorType\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Brief observations from bivariate analysis*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Analysis for Categorical variables with label variable (Revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### **Hypothesis 1**\n",
    "  - Ho : Browser type is independent of the revenue(either purchased made or not) of customers \n",
    "  - Ha : Browser type is not independent of the revenue(either purchased made or not) of customers\n",
    "\n",
    "\n",
    "  Using that alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=UserCookiesData, x='Browser', hue=\"Revenue\" , palette =[\"yellow\", \"blue\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = exploredata.run_chi2(data= UserCookiesData, categorical_var = \"Browser\", target_variable=\"Revenue\")\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1[0]['p-value']< alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### *TakeAways from test 1*\n",
    "    - Since the p-value is greater than alpha (a significance value of 0.05), we failed to reject the null hypothesis that Browser type is independent of a users decision to make purchase.\n",
    "    - We conclude that, a user decision to either make purchase from an online shop is not affected by the type of Browser they user\n",
    "    - This will help us in our next method about feature engineering and feature selection to improve the effectives of some models like the Random forest classifier\n",
    "    - We will not include Browser type in the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hypothesis 2**\n",
    "\n",
    "  + Ho : VisitorType is independent of the purchase decision of the user\n",
    "  + Ha : VisitorType is not independent of the purchase decision of the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=UserCookiesData, x=\"VisitorType\", hue=\"Revenue\", palette=[\"lightgreen\", \"yellow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = exploredata.run_chi2(data=UserCookiesData, categorical_var = \"VisitorType\", target_variable = \"Revenue\")\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2[0][\"p-value\"] < alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### *TakeAways from test 2*\n",
    "    - Since the p-value is less than alpha (a significance value of 0.05), we reject the null hypothesis that Visitor type is independent of a users decision to make purchase.\n",
    "    - We conclude that, a user decision to either make purchase from an online shop is not independent of the Visitors Type (Either returning user or new user)\n",
    "    - This will help us in our next method about feature engineering and feature selection to improve the effectives of some models like the Random forest classifier\n",
    "    - We will include VisitorType in the features for our Random Forest classifer training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### **Hypothesis 3**\n",
    "    * Ho: ProductRelated is independent of the purchase decision of the user\n",
    "    * Ha: ProductRelated is independent of the purchase decison of the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20,10])\n",
    "sns.histplot(data = UserCookiesData,weights=3, x='ProductRelated', hue=\"Revenue\", palette=[\"red\", \"green\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = exploredata.run_chi2(data=UserCookiesData, categorical_var=\"ProductRelated\", target_variable=\"Revenue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3[0]['p-value'] < alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### TakeAways from test 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### **Hypothesis 4**\n",
    "  - Ho:Operating Systems is independent of a users buying decision\n",
    "  - Ha: Operating Systems is not independent of a users buying decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = UserCookiesData, weights=20, x = \"OperatingSystems\", hue = \"Revenue\", palette=[\"Black\", \"Yellow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test4 = exploredata.run_chi2(data=UserCookiesData, categorical_var = \"OperatingSystems\", target_variable = \"Revenue\")\n",
    "test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test4[0]['p-value'] < alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### *TakeAways from test 4*\n",
    "    - Since the p-value is less than the significance value of 0.05, we reject the null hypothesis and infer that the Operating Systems type is not independent of the customers intention to make a purchase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### **Hypothesis 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test5 = exploredata.run_chi2(data = UserCookiesData, categorical_var = \"Weekend\", target_variable = \"Revenue\")\n",
    "test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test5[0]['p-value'] < alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### *TakeAways from test 5*\n",
    "    - Since the p-value is greater than alpha (a significance value of 0.05), we failed to reject the null hypothesis that Weekend is independent of a users decision to make purchase.\n",
    "    - We conclude that, a user decision to either make purchase from an online shop is not affected by the whether the user visits the website on weekends or not\n",
    "    - This pre-informs us that Weekend as a feature will not be used in our feature engineering and feature selection to improve the effectives of some models like the Random forest classifier\n",
    "    - We will not include Weekend in the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hypothesis test 6**\n",
    "\n",
    "  * Ho: The Region location of a customer is independent of the purchasing intent of the customer\n",
    "* Ha: The Region location of a customer is not independent of the purchasing intent of the customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.histplot(data=UserCookiesData, x = \"Region\", hue=\"Revenue\", bins=10, weights=30,palette=\"coolwarm\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test6 = exploredata.run_chi2(data=UserCookiesData, categorical_var=\"Region\", target_variable = \"Revenue\")\n",
    "print(test6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test6[0]['p-value'] < alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### *TakeAways from test 6*\n",
    "   - Since the p-value is greater than the significane value of 0.05, we reject the null hypothesis and a conclsion drawn that the purchasing intent of a customer is not dependent on the Region location of a customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Hypothesis Test Analysis for Quantitative variables with label variable (Revenue)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_vars = ['BounceRates', 'ExitRates', 'PageValues', 'Administrative_Duration','Informational_Duration','ProductRelated_Duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploredata.two_t_test(data = UserCookiesData, quantitative_vars=quant_vars, target_variable = 'Revenue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### ***TakeAways from the levene, mannwhitneyu and shiporo-wilk test for the numerical variables***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Encoding both weekend and the label variable (Revenue) into numeric for modelling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCookiesEncoded = pd.get_dummies(UserCookiesData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCookiesEncoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCookiesEncoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCookiesEncoded[\"Weekend\"] = encoder.fit_transform(UserCookiesEncoded[\"Weekend\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCookiesEncoded[\"Revenue\"] = encoder.fit_transform(UserCookiesEncoded[\"Revenue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCookiesEncoded[\"Revenue\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Data segmentation into training and testing data sets*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = UserCookiesEncoded[\"Revenue\"]\n",
    "x_label = UserCookiesEncoded.drop([\"Revenue\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "x_label=pd.DataFrame(ss.fit_transform(x_label))\n",
    "x_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_label, y_label, test_size =  0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL TRAINING AND TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Random Forest Modelling***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compare_random_classifier_models(x_train, y_train, x_test, y_test):\n",
    "    models_cont = []\n",
    "    for num in range(2, 20):\n",
    "        for val in range(1, 23):\n",
    "            classifier = RandomForestClassifier(n_estimators=50, random_state = 126, max_depth = num, min_samples_leaf = val)\n",
    "            classifier.fit(x_train, y_train)\n",
    "            train_score = classifier.score(x_train, y_train)\n",
    "            predictions = classifier.predict(x_test)\n",
    "\n",
    "            tp = confusion_matrix(y_test, predictions)[1][1]\n",
    "            fp = confusion_matrix(y_test, predictions)[0][1]\n",
    "            tn = confusion_matrix(y_test, predictions)[0][0]\n",
    "            fn = confusion_matrix(y_test, predictions)[1][0]\n",
    "            test_score = classifier.score(x_test, y_test)\n",
    "            eval_params = {\n",
    "                'max_depth':num,\n",
    "                'min_samples_leaf': val,\n",
    "                'True Positves': tp,\n",
    "                'False Positives': fp,\n",
    "                'True Negatives': tn,\n",
    "                'False Negatvies': fn,\n",
    "                'Precision': tp / (tp + fp),\n",
    "                'Recall': tp / (tp + fn),\n",
    "                'Specificity': round(tn / (tn + fp),2),\n",
    "                'Training Accuracy': round(train_score, 2),\n",
    "                'Test Accuracy': round(test_score,2)\n",
    "            }\n",
    "            models_cont.append(eval_params)\n",
    "    return pd.DataFrame(models_cont)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_random_classifier_models(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Feature Engineering for random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCookiesData_ = UserCookiesData.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCookiesData_.drop(['Browser', 'Weekend'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "UserCookiesData_[\"VisitorType\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCookiesData[\"Month\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCookiesData_[\"VisitorType\"].replace([\"Returning_Visitor\",\"New_Visitor\", \"Other\" ], [0,1,2], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCookiesData_[\"Month\"].replace([\"Jan\",\"Feb\", \"Mar\", \"Apr\", \"May\",\"June\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\" ], [0,1,2, 3,4,5,6,7,8,9,10,11], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label_ = UserCookiesData_[\"Revenue\"]\n",
    "x_label_ = UserCookiesData_.drop([\"Revenue\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_, x_test_, y_train_, y_test_ = train_test_split(x_label_, y_label_, test_size =  0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_best_random_forest_classifier(x_train, y_train, x_test, y_test):\n",
    "    classifier = RandomForestClassifier(random_state = 123, max_depth = 394, min_samples_leaf = 19)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    train_score = classifier.score(x_train, y_train)\n",
    "    test_score = classifier.score(x_test, y_test)\n",
    "    predictions = classifier.predict(x_test)\n",
    "    print(predictions)\n",
    "    tp = confusion_matrix(y_test, predictions)[1][1]\n",
    "    fp = confusion_matrix(y_test, predictions)[0][1]\n",
    "    tn = confusion_matrix(y_test, predictions)[0][0]\n",
    "    fn = confusion_matrix(y_test, predictions)[1][0]\n",
    "    test_score = classifier.score(x_test, y_test)\n",
    "    eval_params = {\n",
    "        'max_depth':395,\n",
    "        'min_samples_leaf': 19,\n",
    "        'True Positves': tp,\n",
    "        'False Positives': fp,\n",
    "        'True Negatives': tn,\n",
    "        'False Negatvies': fn,\n",
    "        'Precision': tp / (tp + fp),\n",
    "        'Recall': tp / (tp + fn),\n",
    "        'Specificity': round(tn / (tn + fp),3),\n",
    "        'Training Accuracy': round(train_score, 3),\n",
    "        'Test Accuracy': round(test_score,3)\n",
    "    }\n",
    "    test_results = [eval_params]\n",
    "    test_df = pd.DataFrame(test_results)\n",
    "    return classifier, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = test_best_random_forest_classifier(x_train_, y_train_, x_test_, y_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "ax = plt.gca()\n",
    "rfc_disp = RocCurveDisplay.from_estimator(rf_model[0], x_test_, y_test_, ax=ax, alpha=0.8)\n",
    "rfc_disp.plot(ax=ax, alpha=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf_model[0].predict(x_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "cm_1 = confusion_matrix(y_test_, predictions, labels=rf_model[0].classes_)\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=cm_1,display_labels=rf_model[0].classes_)\n",
    "plt.figure(figsize=(2,1))\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "  pc.dump(rf_model[0], f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### HyperParameter Tunning for random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "tuned_rf = RandomForestClassifier(random_state = 123)\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(tuned_rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "tuned_rnf= RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "tuned_rnf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x_test, y_test):\n",
    "    predictions = model.predict(x_test)\n",
    "    errors = abs(predictions - y_test)\n",
    "    mape = 100 * np.mean(errors / y_test)\n",
    "    print('Model Performance')\n",
    "    print()\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(model.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = tuned_rnf.best_estimator_\n",
    "random_accuracy = evaluate(best_random, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_rf_pipeline = pc.load(\n",
    "    open(\"./model.pkl\", \"rb\")\n",
    ")\n",
    "\n",
    "intent_rf_pipeline.predict(x_test_)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***KNN Modelling***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- * With a random choice for k=3, we had an accuracy of 85%, which is a good start for this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### K-Fold cross validation for KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cross_valid = KNeighborsClassifier(n_neighbors=3)\n",
    "cv_scores = cross_val_score(knn_cross_valid, x_train, y_train, cv=5)\n",
    "print(cv_scores)\n",
    "print('cv_scores mean:{}'.format(np.mean(cv_scores, keepdims = True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- * With a K-Fold cross validation for the KNN model we had an improvement in accuracy which is 86%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### GridSearchCv hypertuning for KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knn2 = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': np.arange(1, 25)}\n",
    "knn_gscv = GridSearchCV(knn2, param_grid, cv=5)\n",
    "knn_gscv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_gscv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- * With GridSearchCv hypertuning for the KNN model there was a slight improvement in the models accuracy to 87%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING WITH SMOTE FOR BALANCING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "smote=RandomOverSampler(random_state=42)\n",
    "X_new,Y_new=smote.fit_resample(x_label,y_label)\n",
    "X_new=pd.DataFrame(X_new,columns=x_train.columns)\n",
    "Y_new=pd.DataFrame(Y_new,columns=['Revenue'])\n",
    "X_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X_new,Y_new,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_with_smote=RandomForestClassifier(n_estimators=50,max_depth=16)\n",
    "rf_with_smote.fit(x_train,y_train)\n",
    "print('Train score:',rf_with_smote.score(x_train,y_train))\n",
    "print('Test score:',rf_with_smote.score(x_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d12e26f72a40d5c48233c54861fca038d6a92135fc0e5e920944e69c69b6b29d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
